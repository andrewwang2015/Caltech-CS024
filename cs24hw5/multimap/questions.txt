Multimap Caching Performance
============================

a)  Size of hardware cache lines: 64 bytes



b)  Output of mmperf:

Testing multimap performance:  300000 pairs, 1000000 probes, random keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997144 out of 1000000 test-pairs were in the map (99.7%)
Total wall-clock time:  51.27 seconds       μs per probe:  51.267 μs

Testing multimap performance:  300000 pairs, 1000000 probes, incrementing keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997715 out of 1000000 test-pairs were in the map (99.8%)
Total wall-clock time:  82.64 seconds       μs per probe:  82.639 μs

Testing multimap performance:  300000 pairs, 1000000 probes, decrementing keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997325 out of 1000000 test-pairs were in the map (99.7%)
Total wall-clock time:  90.53 seconds       μs per probe:  90.534 μs

Testing multimap performance:  15000000 pairs, 1000000 probes, random keys.
Adding 15000000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
949586 out of 1000000 test-pairs were in the map (95.0%)
Total wall-clock time:  10.53 seconds       μs per probe:  10.528 μs

Testing multimap performance:  100000 pairs, 50000 probes, incrementing keys.
Adding 100000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 50000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
976 out of 50000 test-pairs were in the map (2.0%)
Total wall-clock time:  261.81 seconds      μs per probe:  5236.133 μs

Testing multimap performance:  100000 pairs, 50000 probes, decrementing keys.
Adding 100000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 50000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
980 out of 50000 test-pairs were in the map (2.0%)
Total wall-clock time:  276.29 seconds      μs per probe:  5525.713 μs


c)  Explanation of tests:
We notice that the first three tests probe for data in a small range of keys,
but a larger range of values. Because we are adding many key-value pairs
into our map, we will have keys that have a rather long list of values 
associated with it. Thus, finding the actual node in the map will not take
too long because we are limiting our range of keys, but because the node 
will likely have many associated values, we spend a lot more time traversing
the linked list for the specific value. In summary, these tests focus on 
search time of values.

In the second three tests, we have the reverse: a large range of keys, but a 
smaller range of values. Hence, we have many nodes (corresponding to the
keys), but for each node, we may only have a few associated values. In these
cases, we spend a lot more time finding the specific node as opposed to
searching through its list of values. In summary, these tests focus on the
search time of keys. 


e)  Explanation of your optimizations:

The first optimization I performed was changing the representation of values.
Previously, the values for a specific key were stored as a linked list. 
However, nodes of a linked list may not be contiguous in memory which means
when we traverse these linked lists searching for a value, we are hopping
from some memory locations to others that are not so close to one another and
then having to put them in cache (not a high chance that connected nodes are
in the cache together). Thus, we have extremely poor spatial locality. 
To mitigate this, I converted the linked list representation of values to 
arrays. Because arrays are contiguous in memory, when we traverse these 
values, we have great spatial locality, meaning we can hop from value to value 
very quickly, making use of the cache more. To actually implement this 
optimization, I change the values attribute of multimap_node to be an integer 
array and add two more additional integer attributes for size of array and the 
index location where the next value should be placed. Doing such also allows 
us to remove the useof multimap_value and values_tail which saves us 
additional space which also helps in performance. The only caveat with using 
an array is the need for reallocation when we run out of space. To do this, 
I made a helper function called resize_array which handles the doubling of the 
amount of space in a values array in the event we need to do so. In summary, 
changing the representation of the values from linked lists to arrays allows 
us to access contiguous memory, which is likely cached, as opposed to having 
to load memory from many different locations into the cache. 

The second optimization is doing a similar thing as the first, but with the 
multimap_nodes. Before, each node of the multimap was allocated individually,
and so these nodes of the map are not contiguous in memory. This gives rise
to the same problem where because these nodes are not contiguous in memory,
we likely incur cache misses when we traverse from node to node. To solve this
issue, I used slab allocation which essentially serves as a memory pool to
allocate nodes from. Because these slabs are contiguous in memory, when we 
traverse our tree, hopping from node to node, we will be able to use the 
cache more because these nodes are more localized with respect to one another. 
Regarding actual implementation, I have an array of arrays where each inner 
array is an array/slab of multimap_nodes. I maintain this array of arrays 
(multimap_node **slabs) as a global variable in addition to other global 
variables that keep track of the current state of slabs (essentially to tell
us when we need to resize). Each inner array can contain up to 1,000,000 
multimap_nodes and so with each new multimap_node allocation, we place it in
an inner array (adding a slab if we run out of space). Again, to maintain 
these slabs, we had to write helper functions to initialize and resize (using 
the doubling principle described above). In summary, changing how 
multimap_nodes are allocated by putting them into contiguous arrays reduces
the number of cache misses as we traverse the tree. 


f)  Output of ommperf:

Testing multimap performance:  300000 pairs, 1000000 probes, random keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997144 out of 1000000 test-pairs were in the map (99.7%)
Total wall-clock time:  0.82 seconds        μs per probe:  0.816 μs

Testing multimap performance:  300000 pairs, 1000000 probes, incrementing keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997715 out of 1000000 test-pairs were in the map (99.8%)
Total wall-clock time:  0.80 seconds        μs per probe:  0.800 μs

Testing multimap performance:  300000 pairs, 1000000 probes, decrementing keys.
Adding 300000 randomly generated pairs to multimap.
Keys in range [0, 50), values in range [0, 1000).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 50), values in range [0, 1000).
997325 out of 1000000 test-pairs were in the map (99.7%)
Total wall-clock time:  0.80 seconds        μs per probe:  0.802 μs

Testing multimap performance:  15000000 pairs, 1000000 probes, random keys.
Adding 15000000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 1000000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
949586 out of 1000000 test-pairs were in the map (95.0%)
Total wall-clock time:  0.69 seconds        μs per probe:  0.692 μs

Testing multimap performance:  100000 pairs, 50000 probes, incrementing keys.
Adding 100000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 50000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
976 out of 50000 test-pairs were in the map (2.0%)
Total wall-clock time:  9.65 seconds        μs per probe:  192.992 μs

Testing multimap performance:  100000 pairs, 50000 probes, decrementing keys.
Adding 100000 randomly generated pairs to multimap.
Keys in range [0, 100000), values in range [0, 50).
Probing multimap 50000 times with randomly generated test-pairs.
Keys in range [0, 100000), values in range [0, 50).
980 out of 50000 test-pairs were in the map (2.0%)
Total wall-clock time:  9.56 seconds        μs per probe:  191.130 μs
